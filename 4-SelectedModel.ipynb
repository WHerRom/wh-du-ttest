{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Selected Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is performed xgboost classifier as it is a model that tends to perform better in practical cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET_FLAG</th>\n",
       "      <th>AGE</th>\n",
       "      <th>HOME_VAL</th>\n",
       "      <th>OLDCLAIM</th>\n",
       "      <th>CAR_AGE</th>\n",
       "      <th>Doctor</th>\n",
       "      <th>Home Maker</th>\n",
       "      <th>Lawyer</th>\n",
       "      <th>Manager</th>\n",
       "      <th>Professional</th>\n",
       "      <th>Student</th>\n",
       "      <th>Panel Truck</th>\n",
       "      <th>Sports Car</th>\n",
       "      <th>Van</th>\n",
       "      <th>PCA_FACTOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.403128</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.972189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>12.457811</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.125707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11.729576</td>\n",
       "      <td>10.563336</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>12.632160</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.027922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>12.404616</td>\n",
       "      <td>9.863551</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.807560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET_FLAG   AGE   HOME_VAL   OLDCLAIM  CAR_AGE  Doctor  Home Maker  \\\n",
       "0          0.0  60.0   1.000000   8.403128     18.0     0.0         0.0   \n",
       "1          0.0  43.0  12.457811   1.000000      1.0     0.0         0.0   \n",
       "2          0.0  35.0  11.729576  10.563336     10.0     0.0         0.0   \n",
       "3          0.0  51.0  12.632160   1.000000      6.0     0.0         0.0   \n",
       "4          0.0  50.0  12.404616   9.863551     17.0     1.0         0.0   \n",
       "\n",
       "   Lawyer  Manager  Professional  Student  Panel Truck  Sports Car  Van  \\\n",
       "0     0.0      0.0           1.0      0.0          0.0         0.0  0.0   \n",
       "1     0.0      0.0           0.0      0.0          0.0         0.0  0.0   \n",
       "2     0.0      0.0           0.0      0.0          0.0         0.0  0.0   \n",
       "3     0.0      0.0           0.0      0.0          0.0         0.0  0.0   \n",
       "4     0.0      0.0           0.0      0.0          0.0         0.0  0.0   \n",
       "\n",
       "   PCA_FACTOR  \n",
       "0   -0.972189  \n",
       "1   -1.125707  \n",
       "2    0.612868  \n",
       "3   -3.027922  \n",
       "4   -0.807560  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"Working_datasets/processed_train.csv\")\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Premodelling process\n",
    "\n",
    "\n",
    "At this stage, it is performed standardization which is required for many machine learning estimators. In this case in particular, it helps to reach the optimal point quickier for the xgboost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_variable = 'TARGET_FLAG'\n",
    "\n",
    "y = df_train[y_variable].values\n",
    "X = df_train.drop(columns=y_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['AGE',\n",
    "                    'HOME_VAL',\n",
    "                    'OLDCLAIM',\n",
    "                    'CAR_AGE',\n",
    "                    'PCA_FACTOR']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),],\n",
    "    remainder='passthrough')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I divide the data set into training and testing. I also use k-fold to search over hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1234\n",
    "n_splits = 4\n",
    "\n",
    "X_training, X_testing, y_training, y_testing \\\n",
    "= train_test_split(X, y, test_size=0.1, random_state=random_state, stratify=y)\n",
    "\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "I use xgboost classifier to ameliorate the performance of the classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(objective='binary:logistic',\n",
    "                      use_label_encoder=False,\n",
    "                      eval_metric='auc',\n",
    "                      random_state='1234')\n",
    "\n",
    "pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('clf', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training\n",
    "\n",
    "I use RandomizedSearchCV to find the best hyperparameters and I define AUC as performing metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 100 candidates, totalling 400 fits\n",
      "0.7027768641802272\n"
     ]
    }
   ],
   "source": [
    "param_grid  = dict(clf__n_estimators  = np.linspace(100, 300, 6).astype(int),\n",
    "                           clf__alpha         = [0.01, 0.05, 0.1, 0.3, 0.5, 1, 10],\n",
    "                           clf__lambda         = [0.01, 0.05, 0.1, 0.3, 0.5, 1])        \n",
    "\n",
    "grid = RandomizedSearchCV(pipe,\n",
    "                          param_distributions=param_grid,\n",
    "                          cv=kf,\n",
    "                          verbose=1,\n",
    "                          scoring='roc_auc',\n",
    "                          random_state=42,\n",
    "                          n_iter=100,\n",
    "                         )\n",
    "grid.fit(X_training, y_training)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "\n",
    "We evaluate the model on the never seen validation set. We got an improvement compared to the baseline. Further feature engineering could help increasing the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5788462131016208"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = grid.predict(X_testing)\n",
    "roc_auc_score(y_testing, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation of predictions\n",
    "Finally, it is created a csv file with the answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"Working_datasets/processed_test.csv\")\n",
    "X = df_test.drop(columns=y_variable)\n",
    "y_pred = grid.predict(X_testing)\n",
    "Submission = pd.DataFrame({'y_pred': y_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dir = 'Submission'\n",
    "\n",
    "if not os.path.exists(new_dir):\n",
    "    os.mkdir(new_dir)\n",
    "    \n",
    "Submission.to_csv(os.path.join(new_dir, 'test_w_answers.csv'), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "Xgboost is perform to ameliorate the performance of the baseline model. It is also used K-folding to find the best hyperparameters. In this case, I do not use gridsearch; instead, I used randomizedsearch as it quickier to converge and it is recommended in the literature. As a final comments,\n",
    "* Xgboost improves the performance of the model but their optimization is more expensive in computer power.\n",
    "* Overfitting was reduced but it stills very large, it is necessary to perform more sophisticated feature engineering to find the right variables or the right transformation for this problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
